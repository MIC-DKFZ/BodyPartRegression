{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acquired-afghanistan",
   "metadata": {},
   "source": [
    "# Train Body Part Regression Model \n",
    "we will exemplary show how to train a Body Part Regression Model. In general it is important to create a very diverse dataset for training with lots of CT volumes (preferable over 1000 volumes) and from several different studies. For demonstration purposes, we will use in this notebook fewer data and only from one study. \n",
    "\n",
    "## 1. Download data \n",
    "First, the data needs to be downloaded. We will use the [CT Lymph Nodes Dataset](https://wiki.cancerimagingarchive.net/display/Public/CT+Lymph+Nodes) from the TCIA. <br> \n",
    "Select the dataset from the [search porta](https://nbia.cancerimagingarchive.net/nbia-search/) and download the data. This will take some minutes. \n",
    "\n",
    "![title](data/tcia-download-data.png)\n",
    "\n",
    "For evaluation purposes, a corresponding landmark file is needed. \n",
    "First, we need to define landmarks, on which we want to evaluate the BPR model. Bone landmarks are more robust than organ landmarks and therefore more suitable. In this example, we will use the landmarks: pelvis-start, femur-end, L5, L3, L1, Th11, Th8, Th5, and Th2. In general, the centroid of the spines work well as evaluation landmarks. The spine landmarks can get automatically annotated with a vertebra [nnU-Net](https://github.com/MIC-DKFZ/nnUNet). \n",
    "For this example a subset of the data has been annotated already and can be found in the excel file: <br>\n",
    "*data/ct-lymph-nodes-annoted-landmarks.xlsx*  <br> \n",
    "For the sake of simplicity, we have in this example only a test and training (and no validation set). \n",
    "\n",
    "\n",
    "## 2. Preprocess data \n",
    "After the data has downloaded the data needs to be preprocessed to npy-arrays. In this example, we will downscale the axial slices to a size of 64 x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "nifti_to_npy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plightning5",
   "language": "python",
   "name": "plightning5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
